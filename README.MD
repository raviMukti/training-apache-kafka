## Training Apache Kafka

Refresh Basic Knowledge About Apache Kafka

- **Apache Kafka** (A distributed streaming platform) atau sederhananya aplikasi yang mempunyai kemampuan publish dan juga subscribe (Mengirim-Menerima) data (messaging)
- **Messaging**, mekanisme messaging sangat sederhana, dimana ada sebuah aplikasi yang mengirim data (Publisher) ke sebuah Topic (pada kafka) dan aplikasi yang menjadi penerima data (Subscriber) akan otomatis menerima data tersebut tanpa harus melakukan query ataupun melakukan http request ke Topic dan kegiatan messaging ini akan di maintain oleh sebuah apps bernama Message Broker, salah satunya adalah Apache Kafka
- **Sebelum Publish-Subscribe (Messaging)**, komunikasi data antar aplikasi menggunakan http request ataupun juga sharing database. Ketika ada aplikasi lain yang membutuhkan data baru maka bisa jadi akan ada API baru yang dibuat, dan bisa saja flow nya jadi makin banyak atau semrawut, dan bisa saja lama kelamaan komunikasi menggunakan http ini akan menjadi lambat dan sering bermasalah, karena traffic atau ada delay dari salah satu apps sehingga request API menjadi lambat
- **Setelah adanya Publish-Subscribe**, komunikasi data antar aplikasi kini menggunakan mekanisme mengirim dan menerima data ke dan dari message broker. Dengan mekanisme ini aplikasi yang membutuhkan data dari aplikasi lain cukup menjadi subscriber dari data (Topic) yang dibutuhkan, dan hebatnya lagi dengan metode ini message broker tahu aplikasi mana yang belum menerima data, sehingga kita tidak perlu khawatir apabila ada salah satu aplikasi yang mengalami kendala atau mati, ini tidak akan mengganggu aplikasi lain, tidak perlu lagi khawatir memikirkan mekanisme retry transfer data atau data hilang ditengah jalan
- **Arsitektur Kafka**, didalam kafka biasanya ada 4 jenis aplikasi diantaranya producer, consumer, connectors dan stream processors. Stream processors disini digunakan untuk mengolah data yang terus mengalir (stream), sedangkan connectors ini adalah fitur dimana kita integrasi dengan aplikasi existing kita, contoh ketika kita ingin mendapatkan perubahan di database tertentu, kita bisa menggunakan fitur connector
- **Kafka Cluster**, Jarang sekali kafka diinstall hanya satu, biasanya terdiri dari banyak aplikasi kafka, dan ini kita sebut cluster (kumpulan) beberapa aplikasi kafka. Dan biasa diinstal dalam jumlah ganjil, karena ketika ada problem network split brand tidak akan mengalami masalah
- **Zoo Keeper**, untuk saat ini kafka tidak bisa berjalan sendiri, kafka butuh aplikasi bernama zoo keeper untuk bisa berjalan, dimana zoo keeper ini nanti berfungsi untuk maintain cluster kafka. Tapi kedepannya kafka akan independent tanpa perlu adanya zoo keeper. Zoo keeper biasanya akan menentukan kafka mana yang akan menjadi master atau slave
- **Topic**, data di kafka disimpan dalam, atau jika di database Topic ini dianalogikan seperti table. Data di Topic bersifat immutable atau tidak bisa diubah. Data di kafka bisa juga dianalogikan sebagai log atau event
- **Topic Partition**, saat kita membuat topic kita bisa menentukan jumlah partisi yang ada dalam topic tersebut. Analoginya jika topic itu dianggap sebagai file, kita akan potong file itu menjadi beberapa file yang lebih kecil. Dengan ini akan lebih mudah untuk di manage. Dan hal ini dikarenakan nanti, satu partisi hanya bisa di consume/subscribe oleh satu aplikasi consumer. Jumlah partisi harus lebih besar dari jumlah aplikasi consumernya.
- **Offset** merupakan posisi terakhir consumer menerima data pada partisi. Dan offset ini di maintain oleh kafka nya sendiri, termasuk partisi dan cara routing by default itu di maintain oleh kafka
- **Replication**, sederhana nya adalah menduplikasi data partisi yang ada. Replikasi partisi ini di handle oleh kafka secara otomatis, namun biasanya tidak pada server yang sama, jadi misalkan kita punya Partisi Primary (P1) di server kafka 1, replikasinya akan berada di Server kafka 2, tidak pada server yang sama. Kenapa seperti itu, ini untuk menghindari kondisi server mati, karena ketika server mati aplikasi tidak bisa menerima atau mengirim data, dan akan ada kehilangan data. Maka dari itu replikasi dilakukan di server yang berbeda, jumlah replikasi tergantung seberapa paranoid kita terhadap kondisi seperti diatas, minimal 1 replikasi lebih banyak lebih baik. Tapi jangan lupa replikasi ini akan meningkatkan kapasitas penyimpanan data
- **Consumer Group**, pada kenyataannya saat kita menjalankan aplikasi yang bersifat production, kita jarang sekali punya 1 aplikasi, biasanya aplikasi nya akan kita buat menjadi minimal 2, dalam penggunaan di arsitektur messaging. **Ketika aplikasi consumer melakukan subscribe ke sebuah Topic, maka aplikasi tersebut akan mengkonsum semua data yang ada pada partisi di topic tersebut**. Seandainya kita menjalankan 2 aplikasi consumer tersebut, maka aplikasi consumer ke dua akan consume data yang sama dari topic tersebut. Nah dengan adanya consumer group, kafka akan melakukan grouping untuk aplikasi consumer yang dikategorikan sama (Payment Service) misalkan. Saat kita group, maka secara otomatis cara mengkonsum data dari partisi akan berubah, tadinya setiap aplikasi akan konsum semua data yang ada di semua partisi, tapi dengan adanya grouping, satu partisi hanya akan di konsum oleh satu aplikasi yang ada pada group yang sama
- Lantas bagaimana ketika kita akan menjalankan aplikasi lain yang berbeda kategorinya (Order Service) misalkan, maka tinggal kita lakukan pembuatan consumer group baru. Jadi dalam 1 consumer group hanya boleh consume 1 topic 
- Jika jumlah partisi kurang dari jumlah aplikasi yang ada di consumer group, maka akan ada aplikasi pada consumer group yang AFK, karena tidak menerima data dari partisi
- Biasanya untuk mempercepat proses di kafka, kita membuat banyak partisi, untuk nantinya di consume oleh aplikasi
- **Retention Policy**, di Kafka sayangnya kita tidak bisa menghapus data yang ada di Kafka secara manual, jika ingin, kita bisa saja menghapus Topic agar datanya hilang. Ya karena bentuknya log/event maka behaviour nya tidak sama dengan database. Kafka tidak peduli meskipun datanya sama, kafka akan terus melakukan append. Karena terus menerus menambahkan data, maka kapasitas size dari kafka akan terus bertambah, untungnya untuk melakukan penghapusan data, kafka bisa melakukannya secara otomatis atau Retention Policy. Ada beberapa cara yang bisa dilakukan untuk melakukan penghapusan data secara otomatis, diantaranya yaitu Log Retention Time dan Log Retention Bytes
- **Log Retention Time**, adalah jeda waktu seberapa lama kita ingin menyimpan data pada kafka, by default kafka akan menyimpan datanya sampai 7 hari, setelahnya data lama akan dihapus, diganti data baru. Tapi Retention Time ini bisa kita ubah, misalkan dari 7 hari menjadi 30 hari. Tapi bisa saja ada kondisi dimana sebelum 30 hari kapasitas harddisk yang digunakan kafka sudah penuh, dan tidak dapat menampung data lagi, nah untuk hal ini kita bisa menggunakan rules berikutnya.
- **Log Retention Bytes**, adalah seberapa besar ukuran partisi yang diperbolehkan.  Jika kita set maksimalnya 1GB maka sebelum 30 hari, jika data sudah mencapai 1GB maka data lama akan dihapus walaupun secara Log Retention Time belum berakhir
- **Offset Retention Time**, setiap consumer ketika consume data akan menyimpan offset terakhir ketika dia consume data. Nah offset retention time itu adalah seberapa lama data offset disimpan di kafka. Ini dilakukan kafka untuk mengetahui aplikasi A sudah konsum data sampai offset mana. Jika banyak aplikasi yang menjadi consumer maka kafka akan menyimpan banyak data offset, dan jika ada kejadian dimana aplikasi yang sebelumnya consume itu tidak dipakai lagi, maka otomatis kafka menyimpan data sampah. Untuk menangani hal ini kafka mempunyai fitur Offset Retention Time, by default kafka lama akan menghapus data offset yang berumur 1 hari. Tapi hati hati jika aplikasinya dinyalakan lagi, maka dia akan konsum data dari awal, karena data offset sebelumnya sudah dihapus. Tapi di kafka terbaru Offset Retention Time nya by default waktunya adalah 7 hari
- Praktek kafka menggunakan Spring bisa di check di repository ini [Spring Kafka](https://github.com/raviMukti/spring-simple-kafka)